{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdhRpHNUsESw",
        "outputId": "56fd9938-7897-4922-c496-baaa22dbf9ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.40.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.7.0)\n",
            "Collecting tomlkit (from pennylane)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.40 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.13.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.40->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (2.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.1.31)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading PennyLane-0.40.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.1-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, tomlkit, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.1 diastatic-malt-2.15.2 pennylane-0.40.0 pennylane-lightning-0.40.0 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 tomlkit-0.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VAwkVF7r8Lp",
        "outputId": "1fe85d0c-78cd-4aa6-a548-18dedf839f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded and processed 10 images.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "QFT-transformed states saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define file paths for the images\n",
        "image_paths = [\n",
        "    \"/content/cat_10.jpeg\", \"/content/cat_11.jpeg\", \"/content/dog_2.jpeg\",\n",
        "    \"/content/dog_3.jpeg\", \"/content/dog_4.jpeg\", \"/content/dog_5.jpeg\", \"/content/dog_6.jpeg\",\n",
        "    \"/content/cat_7.jpeg\", \"/content/cat_8.jpeg\", \"/content/cat_9.jpeg\"\n",
        "]\n",
        "\n",
        "num_qubits = 8  # We can adjust based on how many features we want to encode\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "def load_and_preprocess_images(image_paths):\n",
        "    \"\"\"Load images, resize them to 224x224, and normalize pixel values.\"\"\"\n",
        "    images = []\n",
        "    for image_path in image_paths:\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale (1 channel)\n",
        "        image_resized = cv2.resize(image, (224, 224))  # Resize to 224x224\n",
        "        image_normalized = image_resized / 255.0  # Normalize pixel values to range [0, 1]\n",
        "        images.append(image_normalized)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load and preprocess the images\n",
        "images = load_and_preprocess_images(image_paths)\n",
        "print(f\"Loaded and processed {len(images)} images.\")\n",
        "\n",
        "# Convert images into quantum states using basis encoding\n",
        "def basis_encoding(image_features):\n",
        "    \"\"\"Encodes image features into a quantum state using basis encoding.\"\"\"\n",
        "\n",
        "    # Convert continuous values to binary (Threshold at 0.5)\n",
        "    binary_features = (image_features.flatten() > 0.5).astype(int)  # Flatten to 1D array and threshold\n",
        "\n",
        "    @qml.qnode(dev)\n",
        "    def circuit():\n",
        "        \"\"\"Quantum circuit for basis encoding.\"\"\"\n",
        "        for i in range(num_qubits):\n",
        "            if binary_features[i]:  # If the feature is 1, apply an X gate\n",
        "                qml.PauliX(wires=i)\n",
        "        return qml.state()\n",
        "\n",
        "    return circuit()\n",
        "\n",
        "# Process all images into quantum states\n",
        "quantum_states = []\n",
        "for image in images:\n",
        "    quantum_state = basis_encoding(image)\n",
        "    quantum_states.append(quantum_state)\n",
        "    print(f\"Encoded image into quantum state.\")\n",
        "\n",
        "# Convert quantum states to numpy array for further processing\n",
        "quantum_states = np.array(quantum_states)\n",
        "\n",
        "# Quantum Fourier Transform (QFT) to apply on quantum states\n",
        "def qft(wires):\n",
        "    \"\"\"Applies Quantum Fourier Transform (QFT) on the given qubits.\"\"\"\n",
        "    n = len(wires)\n",
        "\n",
        "    for i in range(n):\n",
        "        qml.Hadamard(wires=i)\n",
        "        for j in range(i+1, n):\n",
        "            qml.ControlledPhaseShift(np.pi / 2**(j - i), wires=[j, i])\n",
        "\n",
        "    # Reverse qubit order (QFT convention)\n",
        "    for i in range(n // 2):\n",
        "        qml.SWAP(wires=[i, n - i - 1])\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def apply_qft(state):\n",
        "    \"\"\"Quantum circuit to apply QFT on an input quantum state.\"\"\"\n",
        "    qml.StatePrep(state, wires=range(num_qubits))  # Load state\n",
        "    qft(wires=range(num_qubits))  # Apply QFT\n",
        "    return qml.state()\n",
        "\n",
        "# Apply QFT on each quantum-encoded image\n",
        "qft_transformed_states = []\n",
        "for state in quantum_states:\n",
        "    transformed_state = apply_qft(state)\n",
        "    qft_transformed_states.append(transformed_state)\n",
        "\n",
        "# Convert to numpy array\n",
        "qft_transformed_states = np.array(qft_transformed_states)\n",
        "\n",
        "\n",
        "# You can also save the quantum states after QFT transformation for further analysis if needed\n",
        "np.save(\"/content/qft_transformed_images.npy\", qft_transformed_states)\n",
        "print(\"QFT-transformed states saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import seaborn as sns\n",
        "\n",
        "# Define file paths for the images\n",
        "image_paths = [\n",
        "    \"/content/cat_10.jpeg\", \"/content/cat_11.jpeg\", \"/content/dog_2.jpeg\",\n",
        "    \"/content/dog_3.jpeg\", \"/content/dog_4.jpeg\", \"/content/dog_5.jpeg\", \"/content/dog_6.jpeg\",\n",
        "    \"/content/cat_7.jpeg\", \"/content/cat_8.jpeg\", \"/content/cat_9.jpeg\"\n",
        "]\n",
        "\n",
        "# True labels for the images (replace with your actual true labels)\n",
        "true_labels = np.array([1,1, 0,0,0,0,0,1,1,1])  # Example labels\n",
        "\n",
        "# Quantum device setup: Adjust the number of qubits depending on how you want to encode features\n",
        "num_qubits = 8  # Adjust based on how many features you want to encode\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "def load_and_preprocess_images(image_paths):\n",
        "    \"\"\"Load images, resize them to 224x224, and normalize pixel values.\"\"\"\n",
        "    images = []\n",
        "    for image_path in image_paths:\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale (1 channel)\n",
        "        image_resized = cv2.resize(image, (224, 224))  # Resize to 224x224\n",
        "        image_normalized = image_resized / 255.0  # Normalize pixel values to range [0, 1]\n",
        "        images.append(image_normalized)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load and preprocess the images\n",
        "images = load_and_preprocess_images(image_paths)\n",
        "print(f\"Loaded and processed {len(images)} images.\")\n",
        "\n",
        "# Convert images into quantum states using basis encoding\n",
        "def basis_encoding(image_features):\n",
        "    \"\"\"Encodes image features into a quantum state using basis encoding.\"\"\"\n",
        "\n",
        "    # Convert continuous values to binary (Threshold at 0.5)\n",
        "    binary_features = (image_features.flatten() > 0.5).astype(int)  # Flatten to 1D array and threshold\n",
        "\n",
        "    @qml.qnode(dev)\n",
        "    def circuit():\n",
        "        \"\"\"Quantum circuit for basis encoding.\"\"\"\n",
        "        for i in range(num_qubits):\n",
        "            if binary_features[i]:  # If the feature is 1, apply an X gate\n",
        "                qml.PauliX(wires=i)\n",
        "        return qml.state()\n",
        "\n",
        "    return circuit()\n",
        "\n",
        "# Process all images into quantum states\n",
        "quantum_states = []\n",
        "for image in images:\n",
        "    quantum_state = basis_encoding(image)\n",
        "    quantum_states.append(quantum_state)\n",
        "    print(f\"Encoded image into quantum state.\")\n",
        "\n",
        "# Convert quantum states to numpy array for further processing\n",
        "quantum_states = np.array(quantum_states)\n",
        "\n",
        "# Quantum Fourier Transform (QFT) to apply on quantum states\n",
        "def qft(wires):\n",
        "    \"\"\"Applies Quantum Fourier Transform (QFT) on the given qubits.\"\"\"\n",
        "    n = len(wires)\n",
        "\n",
        "    for i in range(n):\n",
        "        qml.Hadamard(wires=i)\n",
        "        for j in range(i+1, n):\n",
        "            qml.ControlledPhaseShift(np.pi / 2**(j - i), wires=[j, i])\n",
        "\n",
        "    # Reverse qubit order (QFT convention)\n",
        "    for i in range(n // 2):\n",
        "        qml.SWAP(wires=[i, n - i - 1])\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def apply_qft(state):\n",
        "    \"\"\"Quantum circuit to apply QFT on an input quantum state.\"\"\"\n",
        "    qml.StatePrep(state, wires=range(num_qubits))  # Load state\n",
        "    qft(wires=range(num_qubits))  # Apply QFT\n",
        "    return qml.state()\n",
        "\n",
        "# Apply QFT on each quantum-encoded image\n",
        "qft_transformed_states = []\n",
        "for state in quantum_states:\n",
        "    transformed_state = apply_qft(state)\n",
        "    qft_transformed_states.append(transformed_state)\n",
        "\n",
        "# Convert to numpy array\n",
        "qft_transformed_states = np.array(qft_transformed_states)\n",
        "\n",
        "# Flatten the QFT states for classification (we'll use a classical classifier)\n",
        "qft_flattened = np.abs(qft_transformed_states).reshape(len(qft_transformed_states), -1)\n",
        "\n",
        "# Train a classical classifier (e.g., K-Nearest Neighbors)\n",
        "clf = KNeighborsClassifier(n_neighbors=3)\n",
        "clf.fit(qft_flattened, true_labels)\n",
        "\n",
        "# Predict on the same set (just for demonstration)\n",
        "predicted_labels = clf.predict(qft_flattened)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEvus8o8sfcO",
        "outputId": "337235ff-8839-42ac-ad06-449f6078f130"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded and processed 10 images.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n",
            "Encoded image into quantum state.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression  # Example classifier for prediction\n",
        "image_paths = [\n",
        "    \"/content/cat_10.jpeg\", \"/content/cat_11.jpeg\", \"/content/dog_2.jpeg\",\n",
        "    \"/content/dog_3.jpeg\", \"/content/dog_4.jpeg\", \"/content/dog_5.jpeg\", \"/content/dog_6.jpeg\",\n",
        "    \"/content/cat_7.jpeg\", \"/content/cat_8.jpeg\", \"/content/cat_9.jpeg\"\n",
        "]\n",
        "\n",
        "\n",
        "# Quantum device setup\n",
        "num_qubits = 8  # Set the number of qubits based on the feature size\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "# Function to perform Amplitude Encoding\n",
        "def amplitude_encoding(image_path):\n",
        "    \"\"\"Encode image into quantum state using Amplitude Encoding.\"\"\"\n",
        "    # Load and process the image\n",
        "    img = Image.open(image_path).convert(\"L\")  # Convert image to grayscale\n",
        "    img = np.array(img)  # Convert to numpy array\n",
        "    img = img.flatten()  # Flatten the image to 1D array\n",
        "    img = img / np.linalg.norm(img)  # Normalize the values to [0,1] range\n",
        "\n",
        "    # Check if the image has more pixels than qubits\n",
        "    if len(img) > num_qubits:\n",
        "        img = img[:num_qubits]  # Truncate to fit the number of qubits\n",
        "    elif len(img) < num_qubits:\n",
        "        img = np.pad(img, (0, num_qubits - len(img)), 'constant')  # Pad with zeros if needed\n",
        "\n",
        "    @qml.qnode(dev)\n",
        "    def circuit():\n",
        "        \"\"\"Quantum circuit for amplitude encoding.\"\"\"\n",
        "        # Apply the image data as amplitudes for the quantum state\n",
        "        for i in range(num_qubits):\n",
        "            qml.RX(2 * np.arccos(img[i]), wires=i)  # Use RX gate to encode image values\n",
        "\n",
        "        return qml.state()\n",
        "\n",
        "    # Execute the circuit to get the quantum state\n",
        "    return circuit()\n",
        "\n",
        "# Process and encode all images\n",
        "quantum_states = []\n",
        "for image_path in image_paths:\n",
        "    quantum_state = amplitude_encoding(image_path)\n",
        "    quantum_states.append(quantum_state)\n",
        "    print(f\"Encoded {image_path} into quantum state.\")\n",
        "\n",
        "# Save the quantum states as .npy files\n",
        "np.save(\"/content/amplitude_encoded_images.npy\", quantum_states)\n",
        "print(\"Quantum states saved successfully.\")\n",
        "\n",
        "# Extract real and imaginary parts of the quantum states for classification\n",
        "quantum_states_flat = []\n",
        "for state in quantum_states:\n",
        "    # Flatten the state and take real and imaginary parts\n",
        "    real_part = np.real(state)\n",
        "    imag_part = np.imag(state)\n",
        "    quantum_states_flat.append(np.concatenate([real_part, imag_part]))\n",
        "\n",
        "# Convert to numpy array for sklearn\n",
        "quantum_states_flat = np.array(quantum_states_flat)\n",
        "\n",
        "# Train a simple classifier (e.g., Logistic Regression) to classify quantum states\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(quantum_states_flat, true_labels)\n",
        "\n",
        "# Predict the labels\n",
        "predicted_labels = clf.predict(quantum_states_flat)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAaxdZleu9qF",
        "outputId": "7b293219-9be8-463d-a805-cb48a992fa56"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded /content/cat_10.jpeg into quantum state.\n",
            "Encoded /content/cat_11.jpeg into quantum state.\n",
            "Encoded /content/dog_2.jpeg into quantum state.\n",
            "Encoded /content/dog_3.jpeg into quantum state.\n",
            "Encoded /content/dog_4.jpeg into quantum state.\n",
            "Encoded /content/dog_5.jpeg into quantum state.\n",
            "Encoded /content/dog_6.jpeg into quantum state.\n",
            "Encoded /content/cat_7.jpeg into quantum state.\n",
            "Encoded /content/cat_8.jpeg into quantum state.\n",
            "Encoded /content/cat_9.jpeg into quantum state.\n",
            "Quantum states saved successfully.\n"
          ]
        }
      ]
    }
  ]
}